{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from olddatasetclass import Dataset\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from train import Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(shape=[0, 0.05], seed=None):\n",
    "    mean, stddev = shape\n",
    "    return keras.initializers.RandomNormal(\n",
    "        mean=mean, stddev=stddev, seed=seed)\n",
    "\n",
    "\n",
    "def normalize(tensor):\n",
    "    K.l2_normalize(tensor)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_users, num_items, num_tasks, e_dim=16, f_dim=8, reg=0):\n",
    "    \"\"\"\n",
    "    This function is used to get the Att-Mul-MF model described\n",
    "    in the paper.\n",
    "    Args:\n",
    "        :param num_users: number of users in the dataset\n",
    "        :param num_items: number of items in the dataset\n",
    "        :param num_tasks: number of tasks (item genres)\n",
    "        :param e_dim: the embedding dimension\n",
    "        :param f_dim: the preference feature space dimension\n",
    "        :param reg: regularization coefficient\n",
    "    \"\"\"\n",
    "    # Input variables\n",
    "    user_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='user_input')\n",
    "    item_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='item_input')\n",
    "\n",
    "    # Embedding layer\n",
    "    layers = [64, 32, 16, 8] # dummy layers\n",
    "    num_layer = len(layers)\n",
    "\n",
    "    user_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_users, output_dim=e_dim, name='user_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    item_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_items, output_dim=e_dim, name='item_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    mlp_user_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_users, output_dim=int(layers[0]/2),\n",
    "        name='mlp_user_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    mlp_item_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_items, output_dim=int(layers[0]/2),\n",
    "        name='mlp_item_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)   \n",
    "\n",
    "    # Flatten the output tensor\n",
    "    user_latent = keras.layers.Flatten()(user_embedding(user_input))\n",
    "    item_latent = keras.layers.Flatten()(item_embedding(item_input))\n",
    "    mlp_user_latent = keras.layers.Flatten()(mlp_user_embedding(user_input))\n",
    "    mlp_item_latent = keras.layers.Flatten()(mlp_item_embedding(item_input))\n",
    "\n",
    "    # concatenate user latent and item latent, prepare for mlp part\n",
    "    mlp_vector = keras.layers.Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    for idx in range(1, num_layer):\n",
    "        layer = keras.layers.Dense(layers[idx],\n",
    "                                   kernel_regularizer=keras.regularizers.l2(reg),\n",
    "                                   activation='relu', name=\"mlp_layer%d\" %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "        \n",
    "        \n",
    "    # Element-wise product\n",
    "    mf_vector = keras.layers.Multiply()([user_latent, item_latent])\n",
    "    mf_vector = keras.layers.Dense(units=f_dim*num_tasks,\n",
    "                                   activation='relu',\n",
    "                                   kernel_initializer='lecun_uniform',\n",
    "                                   name='mf_vector')(mf_vector)\n",
    "    mf_vector = keras.layers.Reshape((num_tasks, f_dim))(mf_vector)\n",
    "    \n",
    "    weight_vector = keras.layers.Dot(axes=-1, normalize=True)([mf_vector, mlp_vector])\n",
    "    att_vector = keras.layers.Dot(axes=(-1, -2))([weight_vector, mf_vector])\n",
    "    \n",
    "    prediction = keras.layers.Dense(1, activation='sigmoid',\n",
    "                                    kernel_initializer='lecun_uniform',\n",
    "                                    name='prediction')(att_vector) \n",
    "    \n",
    "    # Auxiliary info output\n",
    "    aux_vector = keras.layers.Dense(units=1,\n",
    "                       activation='sigmoid',\n",
    "                       kernel_initializer='lecun_uniform',\n",
    "                       name='aux_vector')(mf_vector)\n",
    "    aux_vector = keras.layers.Reshape\n",
    "        \n",
    "    model = keras.models.Model(inputs=[user_input, item_input],\n",
    "                               outputs=[prediction, aux_vector]) ## weight_vector need to be replaced by real genre info\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "num_users = 6040\n",
    "num_items = 3952\n",
    "\n",
    "dataset = Dataset(args.path, args.dataset)\n",
    "train, testRatings, testNegatives = dataset.train_ratings, dataset.test_ratings, dataset.negatives\n",
    "\n",
    "testRatings_array = testRatings.iloc[:, 1].values.reshape((-1, 1))\n",
    "testNegatives_array = np.asarray(testNegatives.iloc[:, 1].tolist())\n",
    "testSamples = np.concatenate((testRatings_array, testNegatives_array), axis=1)\n",
    "\n",
    "# Create user and item input samples\n",
    "shape = testSamples.shape\n",
    "testSamples = testSamples.reshape(-1, 1)\n",
    "userSamples = np.asarray(range(shape[0])).repeat(shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 18, 8]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fb8628075408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestSamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-9a3447173b00>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(num_users, num_items, num_tasks, e_dim, f_dim, reg)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# Auxiliary info output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0maux_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0maux_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m                            \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m                            str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m   1478\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 18, 8]"
     ]
    }
   ],
   "source": [
    "model = get_model(num_users, num_items, args.num_tasks, args.e_dim, args.f_dim, args.reg)\n",
    "t0 = time()\n",
    "predictions = model.predict([userSamples, testSamples], batch_size=256)\n",
    "tc = time() - t0\n",
    "print(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24344534, 0.3612441 , 0.6112192 , ..., 0.15881298, 0.04660348,\n",
       "        0.43405923],\n",
       "       [0.6326083 , 0.5067978 , 0.20544946, ..., 0.6113768 , 0.59549826,\n",
       "        0.3335917 ],\n",
       "       [0.        , 0.2485066 , 0.6685312 , ..., 0.14595644, 0.        ,\n",
       "        0.6508298 ],\n",
       "       ...,\n",
       "       [0.20634267, 0.575054  , 0.3939464 , ..., 0.7528407 , 0.29209885,\n",
       "        0.4768925 ],\n",
       "       [0.09732835, 0.07732199, 0.42968753, ..., 0.5620707 , 0.06501652,\n",
       "        0.54728657],\n",
       "       [0.5082979 , 0.27702624, 0.48635542, ..., 0.22422197, 0.        ,\n",
       "        0.2619219 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleTaskModel(num_users, num_items, e_dim=16, f_dim=8, reg=0):\n",
    "    # Input variables\n",
    "    user_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='user_input')\n",
    "    item_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='item_input')\n",
    "\n",
    "    user_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_users, output_dim=e_dim, name='user_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    item_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_items, output_dim=e_dim, name='item_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Flatten the output tensor\n",
    "    user_latent = keras.layers.Flatten()(user_embedding(user_input))\n",
    "    item_latent = keras.layers.Flatten()(item_embedding(item_input))\n",
    "    \n",
    "    # matrix factorization\n",
    "    mf_vector = keras.layers.Multiply()([user_latent, item_latent])\n",
    "    out_vector = keras.layers.Dense(units=f_dim,\n",
    "                                    activation='sigmoid',\n",
    "                                    kernel_initializer='lecun_uniform',\n",
    "                                    name='output_vector')(mf_vector)\n",
    "    model = keras.models.Model(inputs=[user_input, item_input],\n",
    "                               outputs=[out_vector])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single = singleTaskModel(num_users, num_items, args.e_dim, args.f_dim, args.reg)\n",
    "t0 = time()\n",
    "predictions = single.predict([userSamples, testSamples], batch_size=256)\n",
    "tc = time() - t0\n",
    "print(tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummyModel(num_users, num_items, num_tasks, e_dim=16, f_dim=8, reg=0):\n",
    "    # Input variables\n",
    "    user_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='user_input')\n",
    "    item_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='item_input')\n",
    "\n",
    "    user_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_users, output_dim=e_dim, name='user_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    item_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_items, output_dim=e_dim, name='item_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1) \n",
    "    \n",
    "    # Embedding layer\n",
    "    layers = [64, 32, 16, 8] # dummy layers\n",
    "    num_layer = len(layers)\n",
    "    \n",
    "    mlp_user_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_users, output_dim=int(layers[0]/2),\n",
    "        name='mlp_user_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    mlp_item_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_items, output_dim=int(layers[0]/2),\n",
    "        name='mlp_item_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)   \n",
    "    \n",
    "    # Flatten the output tensor\n",
    "    user_latent = keras.layers.Flatten()(user_embedding(user_input))\n",
    "    item_latent = keras.layers.Flatten()(item_embedding(item_input))\n",
    "    mlp_user_latent = keras.layers.Flatten()(mlp_user_embedding(user_input))\n",
    "    mlp_item_latent = keras.layers.Flatten()(mlp_item_embedding(item_input))\n",
    "\n",
    "    \n",
    "    # concatenate user latent and item latent, prepare for mlp part\n",
    "    mlp_vector = keras.layers.Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    for idx in range(1, num_layer):\n",
    "        layer = keras.layers.Dense(layers[idx], kernel_regularizer= keras.regularizers.l2(reg),\n",
    "                                   activation='relu', name=\"mlp_layer%d\" %idx)\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "        \n",
    "        \n",
    "    # Element-wise product\n",
    "    mf_vector = keras.layers.Multiply()([user_latent, item_latent])\n",
    "    mf_vector = keras.layers.Dense(units=f_dim*num_tasks,\n",
    "                                    activation='sigmoid',\n",
    "                                    kernel_initializer='lecun_uniform',\n",
    "                                    name='output_vector')(mf_vector)\n",
    "    mf_vector = keras.layers.Reshape((num_tasks, f_dim))(mf_vector)\n",
    "    \n",
    "    weight_vector = keras.layers.Dot(axes=-1, normalize=True)([mf_vector, mlp_vector])\n",
    "    att_vector = keras.layers.Dot(axes=(-1, -2))([weight_vector, mf_vector])\n",
    "    \n",
    "    prediction = keras.layers.Dense(1, activation='sigmoid',\n",
    "                                    kernel_initializer='lecun_uniform',\n",
    "                                    name='prediction')(att_vector)    \n",
    "        \n",
    "    model = keras.models.Model(inputs=[user_input, item_input],\n",
    "                               outputs=[prediction])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = dummyModel(num_users, num_items, args.num_tasks, args.e_dim, args.f_dim, args.reg)\n",
    "t0 = time()\n",
    "predictions = dummy.predict([userSamples, testSamples], batch_size=256)\n",
    "tc = time() - t0\n",
    "print(tc)\n",
    "# print(predictions[0].shape)\n",
    "# print(predictions[1].shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.dot(x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(range(24))\n",
    "a = a.reshape((2,3,4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(3), Dimension(4)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.constant(a, dtype=float)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = keras.layers.Dense(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = dense(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(2, 3, 5) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
