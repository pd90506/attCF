{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "from time import time\n",
    "from olddatasetclass import Dataset\n",
    "from evaluate import evaluate_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from item_to_genre import item_to_genre\n",
    "import pandas as pd\n",
    "from aux_loss import aux_crossentropy_loss\n",
    "from utils import get_train_instances\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return x/(tf.norm(x) + 1)\n",
    "\n",
    "norm_layer = keras.layers.Lambda(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28989795 0.28989795 0.5797959 ]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,1,2], dtype='float32')\n",
    "y = normalize(x)\n",
    "sess = tf.Session()\n",
    "print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(shape=[0, 0.05], seed=None):\n",
    "    mean, stddev = shape\n",
    "    return keras.initializers.RandomNormal(\n",
    "        mean=mean, stddev=stddev, seed=seed)\n",
    "\n",
    "\n",
    "def normalize(tensor):\n",
    "    K.l2_normalize(tensor)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def get_model(num_users, num_items, num_tasks,\n",
    "              e_dim=16, mlp_layer=[32], reg=0):\n",
    "    \"\"\"\n",
    "    This function is used to get the Att-Mul-MF model described\n",
    "    in the paper.\n",
    "    Args:\n",
    "        :param num_users: number of users in the dataset\n",
    "        :param num_items: number of items in the dataset\n",
    "        :param num_tasks: number of tasks (item genres)\n",
    "        :param e_dim: the embedding dimension\n",
    "        :param f_dim: the preference feature space dimension\n",
    "        :param reg: regularization coefficient\n",
    "    \"\"\"\n",
    "    num_layer = len(mlp_layer)\n",
    "    # Input variables\n",
    "    user_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='user_input')\n",
    "    item_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='item_input')\n",
    "\n",
    "    user_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_users, output_dim=int(e_dim),\n",
    "        name='user_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    item_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_items, output_dim=int(e_dim),\n",
    "        name='item_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "#     aux_item_embedding = keras.layers.Embedding(\n",
    "#         input_dim=num_items, output_dim=int(mlp_layer[0]),\n",
    "#         name='aux_item_embedding',\n",
    "#         embeddings_initializer=init_normal(),\n",
    "#         embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "#         input_length=1)\n",
    "\n",
    "    # Flatten the output tensor\n",
    "    user_latent = keras.layers.Flatten()(user_embedding(user_input))\n",
    "    item_latent = keras.layers.Flatten()(item_embedding(item_input))\n",
    "#     aux_item_latent = keras.layers.Flatten()(aux_item_embedding(item_input))\n",
    "\n",
    "    # GMF layer\n",
    "    gmf_vector = keras.layers.Multiply()([user_latent, item_latent])\n",
    "\n",
    "\n",
    "    # item vector feature extraction, split at the last layer\n",
    "#     for idx in range(1, num_layer-1):\n",
    "#         layer = keras.layers.Dense(\n",
    "#             units=mlp_layer[idx],\n",
    "#             activation='relu',\n",
    "#             kernel_initializer='lecun_uniform',\n",
    "#             kernel_regularizer=keras.regularizers.l2(reg),\n",
    "#             name='aux_item_layer_{:d}'.format(idx))\n",
    "#         aux_item_latent = layer(aux_item_latent)\n",
    "\n",
    "    # create multitask item output.\n",
    "    item_feature_list = []  # all item features are stored here\n",
    "    for idx in range(0, num_tasks):\n",
    "        layer = keras.layers.Dense(\n",
    "            units=e_dim,\n",
    "            activation='relu',\n",
    "            kernel_initializer='lecun_uniform',\n",
    "            kernel_regularizer=keras.regularizers.l2(reg),\n",
    "            name='item_task_feature_{:d}'.format(idx))\n",
    "\n",
    "        item_feature = layer(item_latent)\n",
    "        item_feature = norm_layer(item_feature)\n",
    "        item_feature_list.append(item_feature)\n",
    "\n",
    "    item_out_list = []   # all item outputs are stored here\n",
    "    for idx in range(0, num_tasks):\n",
    "        layer = keras.layers.Dense(\n",
    "            units=1,\n",
    "            activation='relu',\n",
    "            kernel_initializer='lecun_uniform',\n",
    "            kernel_regularizer=keras.regularizers.l2(reg),\n",
    "            kernel_constraint=keras.constraints.NonNeg(),\n",
    "            name='item_task_out_{:d}'.format(idx))\n",
    "\n",
    "        item_task_output = layer(item_feature_list[idx])\n",
    "        item_out_list.append(item_task_output)\n",
    "\n",
    "    item_outputs = keras.layers.Concatenate(name='item_outputs')(item_out_list)\n",
    "\n",
    "\n",
    "    # Compute attention scores use item_feature_list\n",
    "    item_feature_matrix = keras.layers.Concatenate()(item_feature_list)\n",
    "    item_feature_matrix = keras.layers.Reshape(\n",
    "        (num_tasks, mlp_layer[-1]))(item_feature_matrix)\n",
    "    weight_vector = keras.layers.Dot(axes=(-1, -1))(\n",
    "        [item_feature_matrix, gmf_vector])\n",
    "\n",
    "#     weight_vector = keras.layers.Activation('softmax')(weight_vector)\n",
    "    att_vector = keras.layers.Dot(axes=(-1, -2), name='attention_layer')(\n",
    "        [weight_vector, item_feature_matrix])\n",
    "    \n",
    "    subtracted_vector = keras.layers.Subtract()([gmf_vector, att_vector])\n",
    "    subtracted_out = keras.layers.Dot(axes=(-1, -1), name='l2_norm')([subtracted_vector, subtracted_vector])\n",
    "    # att_vector = keras.layers.Flatten(name='attention_layer')(att_vector)\n",
    "\n",
    "    #  Concatenate mlp_vector and att_vector\n",
    "    # pred_vector = keras.layers.Concatenate()([gmf_vsector, att_vector])\n",
    "\n",
    "    prediction = keras.layers.Dense(\n",
    "        units=1, activation='sigmoid',\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg),\n",
    "        kernel_constraint=keras.constraints.NonNeg(),\n",
    "        name='prediction')(gmf_vector)\n",
    "\n",
    "    model = keras.models.Model(inputs=[user_input, item_input],\n",
    "                               outputs=[prediction, item_outputs, subtracted_out])\n",
    "    att_out = keras.models.Model(inputs=[user_input, item_input],\n",
    "                               outputs=[weight_vector])\n",
    "    return (model, att_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att_cf arguments: ['ml-1m', 32, [256, 128, 64, 32]] \n",
      "Load data done [11.9 s]. #user=6040, #item=3952, #train=6040, #test=6040\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "item_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 32)        126464      item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 32)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "user_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_0 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_1 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_2 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_3 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_4 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_5 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_6 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_7 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_8 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_9 (Dense)     (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_10 (Dense)    (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_11 (Dense)    (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_12 (Dense)    (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_13 (Dense)    (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_14 (Dense)    (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_15 (Dense)    (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_16 (Dense)    (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_feature_17 (Dense)    (None, 32)           1056        flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 32)        193280      user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 32)           0           item_task_feature_0[0][0]        \n",
      "                                                                 item_task_feature_1[0][0]        \n",
      "                                                                 item_task_feature_2[0][0]        \n",
      "                                                                 item_task_feature_3[0][0]        \n",
      "                                                                 item_task_feature_4[0][0]        \n",
      "                                                                 item_task_feature_5[0][0]        \n",
      "                                                                 item_task_feature_6[0][0]        \n",
      "                                                                 item_task_feature_7[0][0]        \n",
      "                                                                 item_task_feature_8[0][0]        \n",
      "                                                                 item_task_feature_9[0][0]        \n",
      "                                                                 item_task_feature_10[0][0]       \n",
      "                                                                 item_task_feature_11[0][0]       \n",
      "                                                                 item_task_feature_12[0][0]       \n",
      "                                                                 item_task_feature_13[0][0]       \n",
      "                                                                 item_task_feature_14[0][0]       \n",
      "                                                                 item_task_feature_15[0][0]       \n",
      "                                                                 item_task_feature_16[0][0]       \n",
      "                                                                 item_task_feature_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 32)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 576)          0           lambda[72][0]                    \n",
      "                                                                 lambda[73][0]                    \n",
      "                                                                 lambda[74][0]                    \n",
      "                                                                 lambda[75][0]                    \n",
      "                                                                 lambda[76][0]                    \n",
      "                                                                 lambda[77][0]                    \n",
      "                                                                 lambda[78][0]                    \n",
      "                                                                 lambda[79][0]                    \n",
      "                                                                 lambda[80][0]                    \n",
      "                                                                 lambda[81][0]                    \n",
      "                                                                 lambda[82][0]                    \n",
      "                                                                 lambda[83][0]                    \n",
      "                                                                 lambda[84][0]                    \n",
      "                                                                 lambda[85][0]                    \n",
      "                                                                 lambda[86][0]                    \n",
      "                                                                 lambda[87][0]                    \n",
      "                                                                 lambda[88][0]                    \n",
      "                                                                 lambda[89][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 32)           0           flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 18, 32)       0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 18)           0           reshape_4[0][0]                  \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (Dot)           (None, 32)           0           dot_4[0][0]                      \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_0 (Dense)         (None, 1)            33          lambda[72][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_1 (Dense)         (None, 1)            33          lambda[73][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_2 (Dense)         (None, 1)            33          lambda[74][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_3 (Dense)         (None, 1)            33          lambda[75][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_4 (Dense)         (None, 1)            33          lambda[76][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_5 (Dense)         (None, 1)            33          lambda[77][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_6 (Dense)         (None, 1)            33          lambda[78][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_7 (Dense)         (None, 1)            33          lambda[79][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_8 (Dense)         (None, 1)            33          lambda[80][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_9 (Dense)         (None, 1)            33          lambda[81][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_10 (Dense)        (None, 1)            33          lambda[82][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_11 (Dense)        (None, 1)            33          lambda[83][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_12 (Dense)        (None, 1)            33          lambda[84][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_13 (Dense)        (None, 1)            33          lambda[85][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_14 (Dense)        (None, 1)            33          lambda[86][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_15 (Dense)        (None, 1)            33          lambda[87][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_16 (Dense)        (None, 1)            33          lambda[88][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "item_task_out_17 (Dense)        (None, 1)            33          lambda[89][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 32)           0           multiply_4[0][0]                 \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_outputs (Concatenate)      (None, 18)           0           item_task_out_0[0][0]            \n",
      "                                                                 item_task_out_1[0][0]            \n",
      "                                                                 item_task_out_2[0][0]            \n",
      "                                                                 item_task_out_3[0][0]            \n",
      "                                                                 item_task_out_4[0][0]            \n",
      "                                                                 item_task_out_5[0][0]            \n",
      "                                                                 item_task_out_6[0][0]            \n",
      "                                                                 item_task_out_7[0][0]            \n",
      "                                                                 item_task_out_8[0][0]            \n",
      "                                                                 item_task_out_9[0][0]            \n",
      "                                                                 item_task_out_10[0][0]           \n",
      "                                                                 item_task_out_11[0][0]           \n",
      "                                                                 item_task_out_12[0][0]           \n",
      "                                                                 item_task_out_13[0][0]           \n",
      "                                                                 item_task_out_14[0][0]           \n",
      "                                                                 item_task_out_15[0][0]           \n",
      "                                                                 item_task_out_16[0][0]           \n",
      "                                                                 item_task_out_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "l2_norm (Dot)                   (None, 1)            0           subtract_4[0][0]                 \n",
      "                                                                 subtract_4[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 339,379\n",
      "Trainable params: 339,379\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: HR = 0.1008, NDCG = 0.0444\n",
      "4970845/4970845 [==============================] - 66s 13us/sample - loss: 0.4946 - prediction_loss: 0.4031 - item_outputs_loss: 0.1444 - l2_norm_loss: 0.0387\n",
      "Iteration 0 [113.4 s]: HR = 0.5397, NDCG = 0.3078, loss = 0.4946 [14.2 s]\n",
      "K2 Iteration 0 [113.4 s]: HR = 0.7296, NDCG = 0.3558, loss = 0.4946 [14.2 s]\n",
      "[[0.03310277 0.0533912  0.         0.00145177 0.         0.\n",
      "  0.         0.04116584 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00056885 0.        ]]\n",
      "4970845/4970845 [==============================] - 64s 13us/sample - loss: 0.3330 - prediction_loss: 0.2871 - item_outputs_loss: 0.0503 - l2_norm_loss: 0.0415\n",
      "Iteration 1 [104.9 s]: HR = 0.6169, NDCG = 0.3513, loss = 0.3330 [14.0 s]\n",
      "K2 Iteration 1 [104.9 s]: HR = 0.7882, NDCG = 0.3949, loss = 0.3330 [14.0 s]\n",
      "[[0.03254514 0.03953579 0.         0.         0.         0.\n",
      "  0.         0.02952419 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]]\n",
      "4970845/4970845 [==============================] - 63s 13us/sample - loss: 0.2904 - prediction_loss: 0.2646 - item_outputs_loss: 0.0155 - l2_norm_loss: 0.0360\n",
      "Iteration 2 [105.0 s]: HR = 0.6505, NDCG = 0.3749, loss = 0.2904 [14.0 s]\n",
      "K2 Iteration 2 [105.0 s]: HR = 0.8113, NDCG = 0.4157, loss = 0.2904 [14.0 s]\n",
      "[[0.03459149 0.03703922 0.         0.         0.         0.\n",
      "  0.         0.02843433 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]]\n",
      "4970845/4970845 [==============================] - 64s 13us/sample - loss: 0.2680 - prediction_loss: 0.2511 - item_outputs_loss: 0.0013 - l2_norm_loss: 0.0325\n",
      "Iteration 3 [105.2 s]: HR = 0.6639, NDCG = 0.3864, loss = 0.2680 [14.3 s]\n",
      "K2 Iteration 3 [105.2 s]: HR = 0.8207, NDCG = 0.4263, loss = 0.2680 [14.3 s]\n",
      "[[0.01518772 0.01478085 0.         0.         0.         0.\n",
      "  0.         0.00617138 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00013519]]\n",
      "4970845/4970845 [==============================] - 64s 13us/sample - loss: 0.2574 - prediction_loss: 0.2423 - item_outputs_loss: 5.3138e-05 - l2_norm_loss: 0.0303\n",
      "Iteration 4 [104.9 s]: HR = 0.6738, NDCG = 0.3996, loss = 0.2574 [14.0 s]\n",
      "K2 Iteration 4 [104.9 s]: HR = 0.8341, NDCG = 0.4403, loss = 0.2574 [14.0 s]\n",
      "[[1.11810155e-02 1.63077936e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.15039013e-03\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.97372569e-05]]\n",
      "4970845/4970845 [==============================] - 64s 13us/sample - loss: 0.2497 - prediction_loss: 0.2352 - item_outputs_loss: 3.5689e-05 - l2_norm_loss: 0.0290\n",
      "Iteration 5 [105.5 s]: HR = 0.6838, NDCG = 0.4074, loss = 0.2497 [14.1 s]\n",
      "K2 Iteration 5 [105.5 s]: HR = 0.8402, NDCG = 0.4470, loss = 0.2497 [14.1 s]\n",
      "[[ 2.6783532e-02  2.9118409e-02  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  2.0776041e-02\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  1.2693587e-03  0.0000000e+00\n",
      "   0.0000000e+00 -2.2477208e-07]]\n",
      "4970845/4970845 [==============================] - 64s 13us/sample - loss: 0.2438 - prediction_loss: 0.2297 - item_outputs_loss: 2.8507e-05 - l2_norm_loss: 0.0282\n",
      "Iteration 6 [105.4 s]: HR = 0.6879, NDCG = 0.4119, loss = 0.2438 [14.0 s]\n",
      "K2 Iteration 6 [105.4 s]: HR = 0.8457, NDCG = 0.4519, loss = 0.2438 [14.0 s]\n",
      "[[0.02464924 0.03216922 0.         0.         0.         0.\n",
      "  0.         0.01910561 0.         0.         0.         0.\n",
      "  0.         0.         0.00260591 0.         0.         0.        ]]\n",
      "4970845/4970845 [==============================] - 64s 13us/sample - loss: 0.2396 - prediction_loss: 0.2258 - item_outputs_loss: 2.5036e-05 - l2_norm_loss: 0.0275\n",
      "Iteration 7 [104.8 s]: HR = 0.6891, NDCG = 0.4139, loss = 0.2396 [14.2 s]\n",
      "K2 Iteration 7 [104.8 s]: HR = 0.8515, NDCG = 0.4552, loss = 0.2396 [14.2 s]\n",
      "[[ 0.01712616  0.02350782  0.          0.          0.          0.\n",
      "   0.          0.01526722  0.          0.          0.          0.\n",
      "   0.          0.          0.00107554  0.         -0.00040958 -0.00096909]]\n",
      "4970845/4970845 [==============================] - 64s 13us/sample - loss: 0.2362 - prediction_loss: 0.2228 - item_outputs_loss: 2.3574e-05 - l2_norm_loss: 0.0269\n",
      "Iteration 8 [105.0 s]: HR = 0.6929, NDCG = 0.4167, loss = 0.2362 [14.0 s]\n",
      "K2 Iteration 8 [105.0 s]: HR = 0.8483, NDCG = 0.4562, loss = 0.2362 [14.0 s]\n",
      "[[0.01054296 0.01408806 0.         0.         0.         0.\n",
      "  0.         0.00719683 0.         0.         0.         0.\n",
      "  0.         0.         0.00064773 0.         0.         0.        ]]\n",
      "4970845/4970845 [==============================] - 64s 13us/sample - loss: 0.2337 - prediction_loss: 0.2206 - item_outputs_loss: 2.4583e-05 - l2_norm_loss: 0.0262\n",
      "Iteration 9 [105.8 s]: HR = 0.6942, NDCG = 0.4174, loss = 0.2337 [14.0 s]\n",
      "K2 Iteration 9 [105.8 s]: HR = 0.8472, NDCG = 0.4561, loss = 0.2337 [14.0 s]\n",
      "[[0.01727902 0.02136636 0.         0.         0.         0.\n",
      "  0.         0.0136655  0.         0.         0.         0.\n",
      "  0.         0.         0.00095459 0.         0.         0.        ]]\n",
      "End. Best Iteration 9:  HR = 0.6942, NDCG = 0.4174. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Args(object):\n",
    "    \"\"\"Used to generate different sets of arguments\"\"\"\n",
    "    def __init__(self):\n",
    "        # default vaules\n",
    "        self.model_name = 'att_cf'\n",
    "        self.path = 'Data/'\n",
    "        self.dataset = 'ml-1m'\n",
    "        self.epochs = 10\n",
    "        self.batch_size = 2024\n",
    "        self.num_tasks = 18\n",
    "        self.e_dim = 32\n",
    "        self.mlp_layer = [256, 128, 64, 32]\n",
    "        self.reg = 0\n",
    "        self.num_neg = 4\n",
    "        self.lr = 0.001\n",
    "        self.loss_weights = [1, 0.5, 0.5]\n",
    "        self.K = 10\n",
    "        self.K2 = 20\n",
    "        self.out = 1\n",
    "        self.gmf_pretrain = ''\n",
    "        self.mlp_pretrain = ''\n",
    "\n",
    "\n",
    "def fit(args=Args()):\n",
    "    # args = Args()\n",
    "    model_out_file = 'Pretrain/%s_%s_%d_%s_%d.h5' %(args.model_name, args.dataset, args.e_dim, args.mlp_layer, time())\n",
    "    result_out_file = 'outputs/%s_%s_top%d_edim%d_layer%s_%d.csv' %(args.model_name, args.dataset,\n",
    "                                                                         args.K, args.e_dim,args.mlp_layer, time())\n",
    "    topK = args.K\n",
    "    topK2 = args.K2\n",
    "    print(\"%s arguments: %s \" % (args.model_name, [args.dataset, args.e_dim, args.mlp_layer]))\n",
    "\n",
    "    # Load data\n",
    "    t1 = time()\n",
    "    if args.dataset == 'ml-1m':\n",
    "        num_users = 6040\n",
    "        num_items = 3952  # need modification\n",
    "    elif args.dataset == 'ml-100k':\n",
    "        num_users = 943\n",
    "        num_items = 1682\n",
    "    elif args.dataset == 'ciao':\n",
    "        num_users = 17615 + 1\n",
    "        num_items = 16121 + 1\n",
    "    else:\n",
    "        raise Exception('wrong dataset size!!!')\n",
    "\n",
    "    dataset = Dataset(args.path, args.dataset)\n",
    "    train, testRatings, testNegatives = (dataset.train_ratings,\n",
    "                                         dataset.test_ratings,\n",
    "                                         dataset.negatives)\n",
    "\n",
    "    print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\"\n",
    "          % (time()-t1, num_users, num_items, train.shape[0],\n",
    "             testRatings.shape[0]))\n",
    "\n",
    "    # Build model, att model is a sub-routine, no need to train it\n",
    "    model, att_out = get_model(num_users,\n",
    "                      num_items,\n",
    "                      num_tasks=args.num_tasks,\n",
    "                      e_dim=args.e_dim,\n",
    "                      mlp_layer=args.mlp_layer,\n",
    "                      reg=args.reg)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=args.lr), loss='binary_crossentropy', loss_weights=args.loss_weights)\n",
    "    print(model.summary())\n",
    "\n",
    "    # Load pretrain model\n",
    "    if args.gmf_pretrain != '' and args.mlp_layer != '':\n",
    "        gmf = att_gmf_model.get_model(num_users, num_items, args.num_tasks, e_dim=args.e_dim, mlp_layer=args.mlp_layer, reg=args.reg)\n",
    "        gmf.load_weights(args.gmf_pretrain)\n",
    "        mlp = att_mlp_model.get_model(num_users, num_items, args.num_tasks, e_dim=args.e_dim, mlp_layer=args.mlp_layer, reg=args.reg)\n",
    "        mlp.load_weights(args.mlp_pretrain)\n",
    "        model = load_pretrain_model(model, gmf, mlp, len(args.mlp_layer),args.num_tasks)\n",
    "        print(\"Load pretrained GMF (%s) and MLP (%s) models done. \" %(args.gmf_pretrain, args.mlp_pretrain))\n",
    "\n",
    "    # Init performance\n",
    "    (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK)\n",
    "    (hits2, ndcgs2) = evaluate_model(model, testRatings, testNegatives, topK2)\n",
    "    hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "    print('Init: HR = %.4f, NDCG = %.4f' % (hr, ndcg))\n",
    "    best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
    "\n",
    "    #dummy_genre = np.random.randn(4970845, args.num_tasks)\n",
    "    \n",
    "    # save Hit ratio and ndcg, loss\n",
    "    output = pd.DataFrame(columns=['hr', 'ndcg', 'loss'])\n",
    "    loss = 1.0 ## TODO\n",
    "    output.loc[0] = [hr, ndcg, loss]\n",
    "\n",
    "    # Training model\n",
    "    for epoch in range(int(args.epochs)):\n",
    "        t1 = time()\n",
    "        # Generate training instances\n",
    "        user_input, item_input, labels = get_train_instances(train, args.num_neg, num_items, args.num_neg)\n",
    "        dummy_genre = item_to_genre(item_input, data_size=args.dataset).values\n",
    "        dummy_genre = np.nan_to_num(dummy_genre)\n",
    "        dummy_sim = np.zeros(len(user_input))\n",
    "         # Training\n",
    "        hist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                         [np.array(labels), dummy_genre, dummy_sim], # labels \n",
    "                         batch_size=args.batch_size, epochs=1, verbose=1, shuffle=True)\n",
    "        t2 = time()\n",
    "\n",
    "        \n",
    "        # Evaluation\n",
    "        if epoch %1 == 0:\n",
    "            (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK)\n",
    "            (hits2, ndcgs2) = evaluate_model(model, testRatings, testNegatives, topK2)\n",
    "            hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]\n",
    "            hr2, ndcg2 = np.array(hits2).mean(), np.array(ndcgs2).mean()\n",
    "            print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]' \n",
    "                  % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "            print('K2 Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]' \n",
    "                  % (epoch,  t2-t1, hr2, ndcg2, loss, time()-t2))\n",
    "            if hr > best_hr:\n",
    "                best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "                if args.out > 0:\n",
    "                    model.save_weights(model_out_file, overwrite=True)\n",
    "\n",
    "            output.loc[epoch+1] = [hr, ndcg, loss]\n",
    "            \n",
    "            # check user 0, item 1286 during training\n",
    "            # 1286: 1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0\n",
    "            u = np.array([0])\n",
    "            i = np.array([1286])\n",
    "            att = att_out.predict([u, i])\n",
    "            print(att)\n",
    "        \n",
    "    \n",
    "            \n",
    "\n",
    "    \n",
    "    output.to_csv(result_out_file, index=False)\n",
    "    print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))\n",
    "    return (model, att_out)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args1 = Args()\n",
    "    model, att_out = fit(args1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    \"\"\"Used to generate different sets of arguments\"\"\"\n",
    "    def __init__(self):\n",
    "        # default vaules\n",
    "        self.model_name = 'att_cf'\n",
    "        self.path = 'Data/'\n",
    "        self.dataset = 'ml-1m'\n",
    "        self.epochs = 20\n",
    "        self.batch_size = 1024\n",
    "        self.num_tasks = 18\n",
    "        self.e_dim = 32\n",
    "        self.mlp_layer = [256, 128, 64, 32]\n",
    "        self.reg = 0\n",
    "        self.num_neg = 4\n",
    "        self.lr = 0.001\n",
    "        self.loss_weights = [1, 0.5, 0.5]\n",
    "        self.K = 10\n",
    "        self.K2 = 20\n",
    "        self.out = 1\n",
    "        self.gmf_pretrain = ''\n",
    "        self.mlp_pretrain = ''\n",
    "args = Args()\n",
    "model, att_out = get_model(6040,\n",
    "                  3952,\n",
    "                  num_tasks=args.num_tasks,\n",
    "                  e_dim=args.e_dim,\n",
    "                  mlp_layer=args.mlp_layer,\n",
    "                  reg=args.reg)\n",
    "\n",
    "u = np.array([0])\n",
    "i = np.array([2251])\n",
    "att = att_out.predict([u, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.array([52])\n",
    "i = np.array([292])\n",
    "att = att_out.predict([u, i])\n",
    "softmax(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07937698,  0.23666833,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.6772463 ,\n",
       "        -0.00465667, -0.00205176,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.array([40])\n",
    "i = np.array([1371])\n",
    "att = att_out.predict([u, i])\n",
    "att/np.sum(np.absolute(att))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14457345]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.array([2871])\n",
    "i = np.array([1371])\n",
    "p = model.predict([u,i])[0]\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02507338, -0.01671254,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.04235794,\n",
       "         0.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.array([12])\n",
    "i = np.array([1371])\n",
    "att = att_out.predict([u, i])\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016627992"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0113492 , 0.00186937, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01200796,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.06310958, 0.        , 0.06819441, 0.        , 0.        ,\n",
       "        0.00252415, 0.        , 0.03397936, 0.04128227, 0.        ,\n",
       "        0.04386356, 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
