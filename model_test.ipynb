{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def init_normal(shape=[0, 0.05], seed=None):\n",
    "    mean, stddev = shape\n",
    "    return keras.initializers.RandomNormal(\n",
    "        mean=mean, stddev=stddev, seed=seed)\n",
    "\n",
    "\n",
    "def normalize(tensor):\n",
    "    K.l2_normalize(tensor)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def get_model(num_users, num_items, num_tasks, e_dim=16, f_dim=8, reg=0):\n",
    "    \"\"\"\n",
    "    This function is used to get the Att-Mul-MF model described\n",
    "    in the paper.\n",
    "    Args:\n",
    "        :param num_users: number of users in the dataset\n",
    "        :param num_items: number of items in the dataset\n",
    "        :param num_tasks: number of tasks (item genres)\n",
    "        :param e_dim: the embedding dimension\n",
    "        :param f_dim: the preference feature space dimension\n",
    "        :param reg: regularization coefficient\n",
    "    \"\"\"\n",
    "    # Input variables\n",
    "    user_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='user_input')\n",
    "    item_input = keras.layers.Input(shape=(1,), dtype='int32',\n",
    "                                    name='item_input')\n",
    "\n",
    "    gmf_user_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_users, output_dim=int(e_dim),\n",
    "        name='gmf_user_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    gmf_item_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_items, output_dim=int(e_dim),\n",
    "        name='gmf_item_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    user_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_users, output_dim=int(f_dim),\n",
    "        name='user_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    item_embedding = keras.layers.Embedding(\n",
    "        input_dim=num_items, output_dim=int(e_dim),\n",
    "        name='item_embedding',\n",
    "        embeddings_initializer=init_normal(),\n",
    "        embeddings_regularizer=keras.regularizers.l2(reg),\n",
    "        input_length=1)\n",
    "\n",
    "    # Flatten the output tensor\n",
    "    gmf_user_latent = keras.layers.Flatten()(gmf_user_embedding(user_input))\n",
    "    gmf_item_latent = keras.layers.Flatten()(gmf_item_embedding(item_input))\n",
    "    user_latent = keras.layers.Flatten()(user_embedding(user_input))\n",
    "    item_latent = keras.layers.Flatten()(item_embedding(item_input))\n",
    "\n",
    "    # GMF part\n",
    "    gmf_vector = keras.layers.Concatenate()([gmf_user_latent, gmf_item_latent])\n",
    "\n",
    "    # user vector feature extraction, split at the last layer\n",
    "    user_vector = keras.layers.Dense(\n",
    "        units=num_tasks*f_dim,\n",
    "        activation='relu',\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg),\n",
    "        name='user_vector')(user_latent)\n",
    "    user_vector = keras.layers.Reshape(\n",
    "        (num_tasks, f_dim), name='multitask_user_vector')(user_vector)\n",
    "\n",
    "    # item vector feature extraction, split at the last layer\n",
    "    item_vector = keras.layers.Dense(\n",
    "        units=num_tasks*f_dim,\n",
    "        activation='relu',\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg),\n",
    "        name='item_vector')(item_latent)\n",
    "    item_vector = keras.layers.Reshape(\n",
    "        (num_tasks, f_dim), name='multitask_item_vector')(item_vector)\n",
    "\n",
    "    weight_vector = keras.layers.Dot(axes=-1, normalize=True)(\n",
    "        [user_vector, item_vector])\n",
    "    weight_vector = tf.linalg.tensor_diag(weight_vector)\n",
    "    att_vector = keras.layers.Dot(axes=(-1, -2))([weight_vector, item_vector])\n",
    "    att_vector = keras.layers.Flatten(name='attention_layer')(att_vector)\n",
    "\n",
    "    #  Concatenate gmf_vector and att_vector\n",
    "    pred_vector = keras.layers.Concatenate()([gmf_vector, att_vector])\n",
    "\n",
    "    prediction = keras.layers.Dense(\n",
    "        units=1, activation='sigmoid',\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg),\n",
    "        name='prediction')(pred_vector)\n",
    "    \n",
    "    aux_vector = keras.layers.Dense(\n",
    "        units=1, activation='sigmoid',\n",
    "        kernel_initializer='lecun_uniform',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg),\n",
    "        name='aux_vector')(item_vector)\n",
    "    aux_vector = keras.layers.Flatten(name='aux_output')(aux_vector)\n",
    "\n",
    "    model = keras.models.Model(inputs=[user_input, item_input],\n",
    "                               outputs=[prediction, aux_vector])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 2 in both shapes must be equal, but are 18 and 8. Shapes are [?,18,18,?] and [?,18,8,1]. for 'dot_6/MatMul' (op: 'BatchMatMul') with input shapes: [?,18,18,?,18,18], [?,18,8,1,1,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 2 in both shapes must be equal, but are 18 and 8. Shapes are [?,18,18,?] and [?,18,8,1]. for 'dot_6/MatMul' (op: 'BatchMatMul') with input shapes: [?,18,18,?,18,18], [?,18,8,1,1,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3b68da9dc2ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                   \u001b[0me_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                   \u001b[0mf_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                   reg=args.reg)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-006c2687767c>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(num_users, num_items, num_tasks, e_dim, f_dim, reg)\u001b[0m\n\u001b[1;32m     93\u001b[0m         [user_vector, item_vector])\n\u001b[1;32m     94\u001b[0m     \u001b[0mweight_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0matt_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweight_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0matt_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'attention_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_type_conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36m_merge_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m       \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_dot\u001b[0;34m(x, y, axes)\u001b[0m\n\u001b[1;32m   1449\u001b[0m       \u001b[0madj_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m       \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madj_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1452\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx_ndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m       return gen_math_ops.batch_mat_mul(\n\u001b[0;32m-> 1980\u001b[0;31m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[0m\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 1236\u001b[0;31m         \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n\u001b[0m\u001b[1;32m   1237\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 instructions)\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1729\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1730\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1731\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 2 in both shapes must be equal, but are 18 and 8. Shapes are [?,18,18,?] and [?,18,8,1]. for 'dot_6/MatMul' (op: 'BatchMatMul') with input shapes: [?,18,18,?,18,18], [?,18,8,1,1,1]."
     ]
    }
   ],
   "source": [
    "class Args(object):\n",
    "    \"\"\"Used to generate different sets of arguments\"\"\"\n",
    "    def __init__(self):\n",
    "        # default vaules\n",
    "        self.path = 'Data/'\n",
    "        self.dataset = 'ml-100k'\n",
    "        self.epochs = 20\n",
    "        self.batch_size = 256\n",
    "        self.num_tasks = 18\n",
    "        self.e_dim = 8\n",
    "        self.f_dim = 8\n",
    "        self.reg = 0\n",
    "        self.num_neg = 4\n",
    "        self.lr = 0.001\n",
    "        self.loss_weights = [1, 0.1]\n",
    "        self.K = 10\n",
    "        # self.learner = 'adam' \n",
    "args=Args()\n",
    "if args.dataset == 'ml-1m':\n",
    "    num_users = 6040\n",
    "    num_items = 3952  # need modification\n",
    "elif args.dataset == 'ml-100k':\n",
    "    num_users = 943\n",
    "    num_items = 1682\n",
    "else:\n",
    "    raise Exception('wrong dataset size!!!')\n",
    "    \n",
    "model = get_model(num_users,\n",
    "                  num_items,\n",
    "                  num_tasks=args.num_tasks,\n",
    "                  e_dim=args.e_dim,\n",
    "                  f_dim=args.f_dim,\n",
    "                  reg=args.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 8)         7544        user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 8)         13456       item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 8)            0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 8)            0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "user_vector (Dense)             (None, 144)          1296        flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "item_vector (Dense)             (None, 144)          1296        flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multitask_user_vector (Reshape) (None, 18, 8)        0           user_vector[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multitask_item_vector (Reshape) (None, 18, 8)        0           item_vector[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gmf_user_embedding (Embedding)  (None, 1, 8)         7544        user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gmf_item_embedding (Embedding)  (None, 1, 8)         13456       item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 18, 18)       0           multitask_user_vector[0][0]      \n",
      "                                                                 multitask_item_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 8)            0           gmf_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 8)            0           gmf_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 18, 8)        0           dot[0][0]                        \n",
      "                                                                 multitask_item_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16)           0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (Flatten)       (None, 144)          0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 160)          0           concatenate_1[0][0]              \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "aux_vector (Dense)              (None, 18, 1)        9           multitask_item_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            161         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Flatten)            (None, 18)           0           aux_vector[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,762\n",
      "Trainable params: 44,762\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=(2, 5, 4) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = tf.constant(np.zeros([2,5,4]), dtype=float)\n",
    "b = tf.constant(np.zeros([2,5,4]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
